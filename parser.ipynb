{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "parser.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7HAlA0SYECU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "add82cea-a8f0-4c10-fc5c-8e3760fba1ed"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.3MB/s \n",
            "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5BpO7ogZVgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "092141f3-1d2f-48df-cb5a-9ef9fe238741"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnoSZoJQYMPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import google.oauth2.credentials\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "\n",
        "import googleapiclient.discovery\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import pymorphy2\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from gensim.models import FastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS-sUnUPYECY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLIENT_SECRETS_FILE = \"client_secret.json\"\n",
        "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
        "API_SERVICE_NAME = 'youtube'\n",
        "API_VERSION = 'v3'\n",
        "os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjPiaZFMYECb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_authenticated_service():\n",
        "    credentials = None\n",
        "    if os.path.exists('token.pickle'):\n",
        "        with open('token.pickle', 'rb') as token:\n",
        "            credentials = pickle.load(token)\n",
        "    #  Check if the credentials are invalid or do not exist\n",
        "    if not credentials or not credentials.valid:\n",
        "        # Check if the credentials have expired\n",
        "        if credentials and credentials.expired and credentials.refresh_token:\n",
        "            credentials.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                CLIENT_SECRETS_FILE, SCOPES)\n",
        "            credentials = flow.run_console()\n",
        " \n",
        "        # Save the credentials for the next run\n",
        "        with open('token.pickle', 'wb') as token:\n",
        "            pickle.dump(credentials, token)\n",
        " \n",
        "    return build(API_SERVICE_NAME, API_VERSION, credentials = credentials)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKn5cpszYECf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "309bf0b9-c580-49d1-a101-91e0dea4ffee"
      },
      "source": [
        "service = get_authenticated_service()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=499464782258-sk1tjt846grh4bartqo42538n81bkb8o.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=Oca5D3MIJ8Zis7bEcswymKY9BS14d5&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/zAGtlvwC0AAI1Fe4hbNYb3jGeQVKxew5tr1Up5cpdXBzyKs3FLLjyNU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEgHauiyYECh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_video_comments(service, **kwargs):\n",
        "    summary = []\n",
        "    results = service.commentThreads().list(**kwargs).execute()\n",
        "    \n",
        "    while results:\n",
        "        for item in results['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            num_like = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
        "            num_reply = item['snippet']['totalReplyCount']\n",
        "            summary.append({\n",
        "                'comment' : comment,\n",
        "                'num_like' : num_like,\n",
        "                'num_reply' : num_reply\n",
        "            })\n",
        " \n",
        "        if 'nextPageToken' in results:\n",
        "            kwargs['pageToken'] = results['nextPageToken']\n",
        "            results = service.commentThreads().list(**kwargs).execute()\n",
        "        else:\n",
        "            break\n",
        " \n",
        "    return pd.DataFrame(summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw3ggUW_YECk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_word(word):\n",
        "    if word.isalpha() and word not in stop_words:\n",
        "        return morph.parse(word)[0].normal_form\n",
        "\n",
        "    \n",
        "def tokenize_sentence(sentence):\n",
        "    words = word_tokenize(sentence)\n",
        "    norm_words = []\n",
        "    for word in words:\n",
        "        cur_word = check_word(word)\n",
        "        if cur_word is not None:\n",
        "            norm_words.append(cur_word)\n",
        "    return norm_words\n",
        "\n",
        "\n",
        "def add_tokenize_columns(df, tokenized_col='tokenize_text', text_for_tokenize='comment', language='russian'):\n",
        "    global stop_words, morph\n",
        "    stop_words = set(stopwords.words(language))\n",
        "    morph = pymorphy2.MorphAnalyzer()\n",
        "    df[tokenized_col] = df[text_for_tokenize].apply(tokenize_sentence)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiBUi4XNYECm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary = get_video_comments(service, part='snippet', videoId='kOvdx1sz--U', textFormat='plainText')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUfhKollYECv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a70c93da-f138-470d-db7d-e13a2e4b72f1"
      },
      "source": [
        "%%timeit\n",
        "add_tokenize_columns(summary)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 3 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krFcv7DOYECy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary = add_tokenize_columns(summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23YHKYpYYEC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "0b1045b9-ac83-4f8a-c59d-1fedd0fcc591"
      },
      "source": [
        "summary"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>num_like</th>\n",
              "      <th>num_reply</th>\n",
              "      <th>tokenize_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Почему пивнухи, горилки , кб работают, а на ту...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[почему, пивнуха, горилка, кб, работать, турник]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ой как не культурно !!!!!\\nНо пиздец как прави...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[ой, культурно, но, пиздец, правильно, ебаный,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Настоящий мужик</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[настоящий, мужик]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Суппер спортсмен правельно всех на х...й посла...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[суппереть, спортсмен, правельный, х, й, посла...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Журналисты продажные🤦‍♂️👍</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[журналист]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2199</th>\n",
              "      <td>Журналюги клоуны и жополизы редкостные</td>\n",
              "      <td>1160</td>\n",
              "      <td>8</td>\n",
              "      <td>[журналюга, клоун, жополиза, редкостный]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2200</th>\n",
              "      <td>Наконец то быдло мэру ответили в его манере! )</td>\n",
              "      <td>1676</td>\n",
              "      <td>9</td>\n",
              "      <td>[наконец, быдло, мэр, ответить, манера]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2201</th>\n",
              "      <td>А в СМИ то не так показывают. Спортсмен то кра...</td>\n",
              "      <td>86</td>\n",
              "      <td>4</td>\n",
              "      <td>[а, сми, показывать, спортсмен, красавчик]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2202</th>\n",
              "      <td>Спортплошадка запрещена, конопля запрещена. Но...</td>\n",
              "      <td>439</td>\n",
              "      <td>29</td>\n",
              "      <td>[спортплошадка, запретить, конопля, запретить,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2203</th>\n",
              "      <td>Красава че сказать</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>[красава, че, сказать]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2204 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                comment  ...                                      tokenize_text\n",
              "0     Почему пивнухи, горилки , кб работают, а на ту...  ...   [почему, пивнуха, горилка, кб, работать, турник]\n",
              "1     Ой как не культурно !!!!!\\nНо пиздец как прави...  ...  [ой, культурно, но, пиздец, правильно, ебаный,...\n",
              "2                                       Настоящий мужик  ...                                 [настоящий, мужик]\n",
              "3     Суппер спортсмен правельно всех на х...й посла...  ...  [суппереть, спортсмен, правельный, х, й, посла...\n",
              "4                             Журналисты продажные🤦‍♂️👍  ...                                        [журналист]\n",
              "...                                                 ...  ...                                                ...\n",
              "2199             Журналюги клоуны и жополизы редкостные  ...           [журналюга, клоун, жополиза, редкостный]\n",
              "2200     Наконец то быдло мэру ответили в его манере! )  ...            [наконец, быдло, мэр, ответить, манера]\n",
              "2201  А в СМИ то не так показывают. Спортсмен то кра...  ...         [а, сми, показывать, спортсмен, красавчик]\n",
              "2202  Спортплошадка запрещена, конопля запрещена. Но...  ...  [спортплошадка, запретить, конопля, запретить,...\n",
              "2203                                 Красава че сказать  ...                             [красава, че, сказать]\n",
              "\n",
              "[2204 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpeAHnbwa7Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = FastText(size=4, window=3, min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5gzC_bncQrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.build_vocab(summary['tokenize_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUTclaUScZau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train(sentences=summary['tokenize_text'], total_examples=len(summary['tokenize_text']), epochs=10) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptgG7urGcrom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}